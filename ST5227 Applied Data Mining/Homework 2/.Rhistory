((1:100)/100)^5/10
setwd("C:/Users/tay.yq.XTRAMAN/Documents/GitHub/Statistics/ST5227 Applied Data Mining/Homework 2")
xy = read.csv('mydataT02a.csv')
View(xy)
X = xy[,1:50]
y = xy[,201]
n = length(y)
LS = solve( t(X) %*% X) %*% t(X) %*% y;  # Least squares estimator of beta
I = diag(c(0, matrix(1, 6, 1)))
I = diag(7)
cv = matrix(0, 100,1)
lambda = matrix(0, 100,1)
for (i in 1:100)
{
lambdai = ((i-1)/100)*0.5 # value of lambda
cvi = 0
for (j in 1:n)
{
bR = solve( t(X[-j,]) %*% X[-j,] + lambdai*I) %*% (t(X[-j,]) %*% y[-j]); # delete-1-out ridge estimator of beta
yje = X[j,] %*% bR  # fitted values
cvi = cvi +(yje-y[j])^2
}
lambda[i] = lambdai;
cv[i] = cvi
}
plot(lambda, cv)
n = length(y)
LS = solve( t(X) %*% X) %*% t(X) %*% y;  # Least squares estimator of beta
I = diag(c(0, matrix(1, 6, 1)))
I = diag(7)
setwd("C:/Users/tay.yq.XTRAMAN/Documents/GitHub/Statistics/ST5227 Applied Data Mining/Homework 2")
xy = read.csv('mydataT02a.csv')
xy = data.matrix(xy)
xy = scale(xy)
X = xy[,1:50]
y = xy[,201]
n = length(y)
LS = solve( t(X) %*% X) %*% t(X) %*% y;  # Least squares estimator of beta
I = diag(c(0, matrix(1, 6, 1)))
I = diag(7)
cv = matrix(0, 100,1)
lambda = matrix(0, 100,1)
setwd("C:/Users/tay.yq.XTRAMAN/Documents/GitHub/Statistics/ST5227 Applied Data Mining/Homework 2")
xy = read.csv('mydataT02a.csv')
xy = data.matrix(xy)
xy = scale(xy)
X = xy[,1:50]
y = xy[,201]
n = length(y)
setwd("C:/Users/tay.yq.XTRAMAN/Documents/GitHub/Statistics/ST5227 Applied Data Mining/Homework 2")
xy = read.csv('mydataT02a.csv')
xy = data.matrix(xy)
xy = scale(xy)
X = xy[,1:50]
y = xy[,201]
n = length(y)
I = diag(50)
cv = matrix(0, 100,1)
lambda = matrix(0, 100,1)
for (i in 1:100)
{
lambdai = ((i-1)/100)*0.5 # value of lambda
cvi = 0
for (j in 1:n)
{
bR = solve( t(X[-j,]) %*% X[-j,] + lambdai*I) %*% (t(X[-j,]) %*% y[-j]); # delete-1-out ridge estimator of beta
yje = X[j,] %*% bR  # fitted values
cvi = cvi +(yje-y[j])^2
}
lambda[i] = lambdai;
cv[i] = cvi
}
plot(lambda, cv)
bestlambda = lambda[which(cv==min(cv))]
lambda = matrix(0, 100, 1)
lambda
setwd("C:/Users/tay.yq.XTRAMAN/Documents/GitHub/Statistics/ST5227 Applied Data Mining/Homework 2")
xy = read.csv('mydataT02a.csv')
xy = data.matrix(xy)
xy = scale(xy)
X = xy[,1:50]
y = xy[,201]
n = length(y)
I = diag(50)
cv = matrix(0, 100,1)
lambda = c(0.1, 1, 10, 100, 1000)
nL = length(lambda)
for (i in 1:nL)
{
lambdai = lambda[i] # value of lambda
cvi = 0
for (j in 1:n)
{
bR = solve( t(X[-j,]) %*% X[-j,] + lambdai*I) %*% (t(X[-j,]) %*% y[-j]); # delete-1-out ridge estimator of beta
yje = X[j,] %*% bR  # fitted values
cvi = cvi +(yje-y[j])^2
}
cv[i] = cvi
}
plot(lambda, cv)
cv
cv = matrix(0, nL, 1)
cv
setwd("C:/Users/tay.yq.XTRAMAN/Documents/GitHub/Statistics/ST5227 Applied Data Mining/Homework 2")
xy = read.csv('mydataT02a.csv')
xy = data.matrix(xy)
xy = scale(xy)
X = xy[,1:50]
y = xy[,201]
n = length(y)
I = diag(50)
lambda = c(0.1, 1, 10, 100, 1000)
nL = length(lambda)
cv = matrix(0, nL, 1)
for (i in 1:nL)
{
lambdai = lambda[i] # value of lambda
cvi = 0
for (j in 1:n)
{
bR = solve( t(X[-j,]) %*% X[-j,] + lambdai*I) %*% (t(X[-j,]) %*% y[-j]); # delete-1-out ridge estimator of beta
yje = X[j,] %*% bR  # fitted values
cvi = cvi +(yje-y[j])^2
}
cv[i] = cvi
}
plot(lambda, cv)
bestlambda = lambda[which(cv==min(cv))]
cv
bestlambda
y[-j]
y
y[-50]
setwd("C:/Users/tay.yq.XTRAMAN/Documents/GitHub/Statistics/ST5227 Applied Data Mining/Homework 2")
xy = read.csv('mydataT02a.csv')
xy = data.matrix(xy)
xy = scale(xy)
X = xy[,1:50]
setwd("C:/Users/tay.yq.XTRAMAN/Documents/GitHub/Statistics/ST5227 Applied Data Mining/Homework 2")
xy = read.csv('mydataT02a.csv')
xy = data.matrix(xy)
xy = scale(xy)
X = xy[,1:50]
y = xy[,201]
n = length(y)
LS = solve( t(X) %*% X) %*% t(X) %*% y;  # Least squares estimator of beta
I = diag(c(0, matrix(1, 6, 1)))
I
I = diag(n)
cv = matrix(0, 100,1)
lambda = matrix(0, 100,1)
for (i in 1:100)
{
lambdai = ((i-1)/100)*0.5 # value of lambda
cvi = 0
for (j in 1:n)
{
bR = solve( t(X[-j,]) %*% X[-j,] + lambdai*I) %*% (t(X[-j,]) %*% y[-j]); # delete-1-out ridge estimator of beta
yje = X[j,] %*% bR  # fitted values
cvi = cvi +(yje-y[j])^2
}
lambda[i] = lambdai;
cv[i] = cvi
}
plot(lambda, cv)
for (i in 1:100)
{
lambdai = (i/100)*0.5 # value of lambda
cvi = 0
for (j in 1:n)
{
bR = solve( t(X[-j,]) %*% X[-j,] + lambdai*I) %*% (t(X[-j,]) %*% y[-j]); # delete-1-out ridge estimator of beta
yje = X[j,] %*% bR  # fitted values
cvi = cvi +(yje-y[j])^2
}
lambda[i] = lambdai;
cv[i] = cvi
}
plot(lambda, cv)
bestlambda = lambda[which(cv==min(cv))]
Ridge = solve( t(X) %*% X + bestlambda*I) %*% t(X) %*% y; # ridge estimator of beta
LS
Ridge
bestlambda
1 / 100 * 0.5
xyNEW = read.csv('mydataT02b.csv')
View(xyNEW)
xyNEW = read.csv('mydataT02b.csv')
xNEW = xyNEW[,1:50]
yNEW = y[,201]
yNEW = xyNEW[,201]
I = diag(n)
I
solve( t(xNEW) %*% xNEW + 0.1*I) %*% t(xNEW) %*% yNEW
xNEW
dim(xNEW)
dim(yNEW)
xyNEW = read.csv('mydataT02b.csv')
xyNEW[, 201]
xyNEW = read.csv('mydataT02b.csv')
xNEW = xyNEW[, 1:50]
yNEW = xyNEW[, 201]
n = length(yNEW)
I = diag(n)
solve( t(xNEW) %*% xNEW + 0.1*I) %*% t(xNEW) %*% yNEW
yNEW
t(xNEW) %*% xNEW + 0.1*I
t(xNEW)
xyNEW = read.csv('mydataT02b.csv')
xNEW = xyNEW[, 1:200]
yNEW = xyNEW[, 201]
n = length(yNEW)
I = diag(n)
I = diag(200)
solve( t(xNEW) %*% xNEW + 0.1*I) %*% t(xNEW) %*% yNEW
dim(xNEW)
t(xNEW)
dim(t(xNEW))
t(xNEW) %*% xNEW
xNEW %*% xNEW
data.matrix
xyNEW = data.matrix(xyNEW)
xNEW = xyNEW[, 1:200]
yNEW = xyNEW[, 201]
n = length(yNEW)
I = diag(200)
solve( t(xNEW) %*% xNEW + 0.1*I) %*% t(xNEW) %*% yNEW
LS = solve( t(xNEW) %*% xNEW + 0.1*I) %*% t(xNEW) %*% yNEW
errorLS = mean((yNEW-XNEW%*%LS)^2)
errorLS = mean((yNEW-xNEW%*%LS)^2)
errorLS
xNEW%*%LS
